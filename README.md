# ğŸ“Š Telegram Medical Business Analytics Platform

A production-grade, scalable data pipeline and analytics API that extracts, processes, and analyzes data from public Ethiopian medical business Telegram channels. This platform includes object detection for image content, a data warehouse for structured storage, and a FastAPI interface for analytical access.

---

## ğŸš€ Project Overview

**Goal:** Build an end-to-end data pipeline that:

* Scrapes medical-related messages and images from Telegram
* Stores and processes raw data in a structured and queryable format
* Detects visual content (e.g. product packaging) using YOLOv8
* Provides RESTful API access to cleaned and enriched data
* Is containerized, automated, and production-ready

---

## ğŸ§° Tools and Technologies

| Component          | Tool / Library          | Purpose                                    |
| ------------------ | ----------------------- | ------------------------------------------ |
| Scraping           | Telethon / Pyrogram     | Extract Telegram data                      |
| Object Detection   | YOLOv8 (ultralytics)    | Analyze images                             |
| Data Storage       | PostgreSQL              | Central data warehouse                     |
| Data Modeling      | dbt                     | Data transformations, tests, documentation |
| API Layer          | FastAPI, Uvicorn        | Serve data via REST API                    |
| Containerization   | Docker, Docker Compose  | Environment & deployment                   |
| Secrets Management | python-dotenv           | Load environment variables                 |
| Orchestration      | Dagster                 | Run, monitor, and schedule pipelines       |
| Logging            | Python `logging` module | Monitoring and debugging                   |

---

## ğŸ“¦ Project Structure

```
my_project/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ telegram_messages/YYYY-MM-DD/
â”‚       â””â”€â”€ images/channel_name/
â”œâ”€â”€ scraper/
â”‚   â””â”€â”€ scrape.py
â”œâ”€â”€ ingestion/
â”‚   â””â”€â”€ load_to_postgres.py
â”œâ”€â”€ enrichment/
â”‚   â””â”€â”€ yolo_detection.py
â”œâ”€â”€ dbt_project/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ dbt_project.yml
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ crud.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ schemas.py
â””â”€â”€ orchestrator/
    â””â”€â”€ dagster_pipeline.py
```

---

## âš™ï¸ Setup & Installation

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/telegram-medical-pipeline.git
cd telegram-medical-pipeline
```

### 2. Add Environment Variables

Create a `.env` file:

```env
TELEGRAM_API_ID=your_api_id
TELEGRAM_API_HASH=your_api_hash
DB_USER=postgres
DB_PASSWORD=yourpassword
DB_NAME=telegram_db
DB_HOST=db
```

### 3. Build Docker Environment

```bash
docker-compose up --build
```

### 4. Run Dagster UI

```bash
dagster dev
```

---

## ğŸ“˜ API Endpoints (Examples)

| Endpoint                                 | Description             |
| ---------------------------------------- | ----------------------- |
| `/api/reports/top-products?limit=10`     | Most mentioned products |
| `/api/channels/{channel}/activity`       | Activity by channel     |
| `/api/search/messages?query=paracetamol` | Keyword search          |

---

## ğŸ“ˆ Data Pipeline

1. **Extract**: Scrape Telegram data (messages, images)
2. **Load**: Store raw data in a data lake (JSON, images)
3. **Transform**: Use `dbt` to model clean and structured tables
4. **Enrich**: Run YOLOv8 for object detection in images
5. **Expose**: Serve data via FastAPI
6. **Orchestrate**: Schedule & monitor via Dagster

---

## âœ… Milestones

### Task 0 - Project Setup

* âœ… Initialized Git repository
* âœ… Created Dockerfile, docker-compose.yml
* âœ… Created requirements.txt
* âœ… Added .env and .gitignore
* âœ… Set up python-dotenv

### Task 1 - Scraping & Data Lake

* âœ… Scraped messages from multiple Telegram channels
* âœ… Collected and stored images
* âœ… Structured raw data in date-partitioned directories
* âœ… Implemented logging for error tracking

### Task 2 - Data Transformation (dbt)

* âœ… Loaded raw JSON into PostgreSQL
* âœ… Created dbt models: staging and marts (dim, fct)
* âœ… Ran tests: not\_null, unique
* âœ… Generated documentation via dbt

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¨â€ğŸ’» Author

Mintesinot Atnafu
[GitHub](https://github.com/minte-atnafu)

---

## ğŸ“¬ Contact

Feel free to open issues or submit pull requests!
